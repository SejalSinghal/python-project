{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04526c3f-22a0-482a-ab5b-dfdf80d6d13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Liabraries\n",
    "\n",
    "from bs4 import BeautifulSoup #This line brings in a tool called BeautifulSoup from a library named bs4.\n",
    "# This tool helps your program understand and work with the structure of web pages, \n",
    "# which are written in a language called HTML\n",
    "# (like how your web browser reads and displays web pages).\n",
    "\n",
    "import requests #requests library  helps the program connect to websites and \n",
    "# get information from them, similar to how a web browser loads a web page when you visit a website\n",
    "import time\n",
    "import datetime\n",
    "#import smtplib (#Used to messsage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7dc75c6a-12e8-4492-95d9-e3df7d6ab052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Analyst T Shirt Funny Gift for Data Analyst Graduate Career Professional Data Analyst Spreadsheet Unisex Tee\n",
      "$23.97 - $31.97\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "#Connect to website\n",
    "URL=\"https://www.amazon.com/Analyst-Graduate-Career-Professional-Spreadsheet/dp/B0C1M17KKT/ref=sr_1_3?dib=eyJ2IjoiMSJ9.3bDrNF-zqGxQ2s-uC94t5rMOAkIpY0cVJ2b6WFM_2aYYw9d7Q2eRFsGcDW5A2htD4mwXcFa_2nu8uLejfcFQgT7gsx9tjFY3itGIqCP0hzE-WNy0gQu2dkLTJb0TaB4vwfgpkKnm6QBw_gu2SAsoNHKpGG2I6S3V_k2V4M6pHfYBild84ejwAVzRw8jKuHVUODYxGQ0ZJ5Lma4FapVGofK-I9LLzHeurVBPqI1gsj6h01Mlvx6zhS7PXxEQwLVdIfD1OpfZk7DBwf9vJbA-8Ez4eyyzZnEx_0EL5q9xpVJM.UOLMBFPEyctGnreq2G2n1NxjCQI9y-xhU1BKe4qO40g&dib_tag=se&keywords=data%2Banalyst%2Btshirts&qid=1717844487&sr=8-3\"\n",
    " # URL of the Amazon product page you want to scrape.\"scrape\" means to extract data from a website\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
    "page=requests.get(URL,headers=headers)\n",
    "soup1= BeautifulSoup(page.content,\"html.parser\")#an \"HTML parser\" is a tool that reads and understands the\n",
    "# structure of a web page\n",
    "soup2=BeautifulSoup(soup1.prettify(),\"html.parser\")\n",
    "\n",
    "\n",
    "title=soup2.find(id=\"productTitle\").get_text().strip()#Strip basically removes the unwanted value withount strip spaces were ther\n",
    "\n",
    "price_range_element = soup2.find(\"span\", class_=\"a-price-range\")\n",
    "prices = price_range_element.find_all(\"span\", class_=\"a-offscreen\")\n",
    "price_min = prices[0].get_text().strip()\n",
    "price_max = prices[1].get_text().strip()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(title)\n",
    "print(price_min,\"-\", price_max)\n",
    "print(type(price_min))\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9cd2bd3d-718e-4a03-939f-cccbf950edbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-09\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "today=datetime.date.today()\n",
    "print(today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1c966d8b-fcc8-4593-b3aa-a8b63ecb7528",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a CSV file\n",
    "\n",
    "import csv\n",
    "header=[\"Title\",\"Min Price\",\"Max Price\",\"Date\"]\n",
    "data=[title,price_min,price_max,today]\n",
    "with open (\"AmazonWebScaperData.csv\",\"w\",newline=\"\",encoding=\"UTF8\") as f:\n",
    "    writer=csv.writer(f)#In first two steps we are creating CSV File\n",
    "    writer.writerow(header)#Creating the haeding of data\n",
    "    writer.writerow(data)\n",
    "\n",
    "#(CSV file name),#it means right,The \"w\" in the open function call specifies the mode in which the file is opened.\n",
    "# In this context, \"w\" stands for \"write,newline=\"\" ensures that the CSV writer uses Unix-style line endings.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7da18ef3-b8a6-498a-94c6-f20c875018a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title Min Price Max Price  \\\n",
      "0  Data Analyst T Shirt Funny Gift for Data Analy...    $23.97    $31.97   \n",
      "\n",
      "         Date  \n",
      "0  2024-06-09  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"C:/Users/sseja/AmazonWebScaperData.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9b2852b4-5cc0-40d9-9ec1-270944d84ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title Min Price Max Price  \\\n",
      "0  Data Analyst T Shirt Funny Gift for Data Analy...    $23.97    $31.97   \n",
      "\n",
      "         Date  \n",
      "0  2024-06-09  \n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\sseja\\AmazonWebScaperData.csv\")#r se you do not need to change back slashes\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ee3b2a3b-7b1c-4abb-a7eb-83c6a13ce5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#append data to csv file\n",
    "\n",
    "with open (\"AmazonWebScaperData.csv\",\"a+\",newline=\"\",encoding=\"UTF8\") as f:\n",
    "    writer=csv.writer(f)#In first two steps we are creating CSV File\n",
    "    writer.writerow(data)\n",
    "    #a+ is used to append the data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "91bd901b-6b7f-4aa2-bc42-4c372582cf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_price():\n",
    "    URL=\"https://www.amazon.com/Analyst-Graduate-Career-Professional-Spreadsheet/dp/B0C1M17KKT/ref=sr_1_3?dib=eyJ2IjoiMSJ9.3bDrNF-zqGxQ2s-uC94t5rMOAkIpY0cVJ2b6WFM_2aYYw9d7Q2eRFsGcDW5A2htD4mwXcFa_2nu8uLejfcFQgT7gsx9tjFY3itGIqCP0hzE-WNy0gQu2dkLTJb0TaB4vwfgpkKnm6QBw_gu2SAsoNHKpGG2I6S3V_k2V4M6pHfYBild84ejwAVzRw8jKuHVUODYxGQ0ZJ5Lma4FapVGofK-I9LLzHeurVBPqI1gsj6h01Mlvx6zhS7PXxEQwLVdIfD1OpfZk7DBwf9vJbA-8Ez4eyyzZnEx_0EL5q9xpVJM.UOLMBFPEyctGnreq2G2n1NxjCQI9y-xhU1BKe4qO40g&dib_tag=se&keywords=data%2Banalyst%2Btshirts&qid=1717844487&sr=8-3\"\n",
    " # URL of the Amazon product page you want to scrape.\"scrape\" means to extract data from a website\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
    "    page=requests.get(URL,headers=headers)\n",
    "    soup1= BeautifulSoup(page.content,\"html.parser\")#an \"HTML parser\" is a tool that reads and understands the\n",
    "# structure of a web page\n",
    "    soup2=BeautifulSoup(soup1.prettify(),\"html.parser\")\n",
    "    title=soup2.find(id=\"productTitle\").get_text().strip()#Strip basically removes the unwanted value withount strip spaces were ther\n",
    "    price_range_element = soup2.find(\"span\", class_=\"a-price-range\")\n",
    "    prices = price_range_element.find_all(\"span\", class_=\"a-offscreen\")\n",
    "    price_min = prices[0].get_text().strip()\n",
    "    price_max = prices[1].get_text().strip()\n",
    "    import datetime\n",
    "    today=datetime.date.today()\n",
    "    \n",
    "    import csv\n",
    "    header=[\"Title\",\"Min Price\",\"Max Price\",\"Date\"]\n",
    "    data=[title,price_min,price_max,today]\n",
    "    with open (\"AmazonWebScaperData.csv\",\"a+\",newline=\"\",encoding=\"UTF8\") as f:\n",
    "        writer=csv.writer(f)#In first two steps we are creating CSV File\n",
    "        writer.writerow(data)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2477bb48-5fed-420d-a6f8-42ef29ec838f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "while(True):\n",
    "    check_price()\n",
    "    time.sleep(86400)#Check price every single day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "3d9a13bb-88f0-4e6e-b9d5-dd40049fecbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title Min Price Max Price  \\\n",
      "0  Data Analyst T Shirt Funny Gift for Data Analy...    $23.97    $31.97   \n",
      "1  Data Analyst T Shirt Funny Gift for Data Analy...    $23.97    $31.97   \n",
      "2  Data Analyst T Shirt Funny Gift for Data Analy...    $23.97    $31.97   \n",
      "3  Data Analyst T Shirt Funny Gift for Data Analy...    $23.97    $31.97   \n",
      "4  Data Analyst T Shirt Funny Gift for Data Analy...    $23.97    $31.97   \n",
      "5  Data Analyst T Shirt Funny Gift for Data Analy...    $23.97    $31.97   \n",
      "6  Data Analyst T Shirt Funny Gift for Data Analy...    $23.97    $31.97   \n",
      "7  Data Analyst T Shirt Funny Gift for Data Analy...    $23.97    $31.97   \n",
      "8  Data Analyst T Shirt Funny Gift for Data Analy...    $23.97    $31.97   \n",
      "9  Data Analyst T Shirt Funny Gift for Data Analy...    $23.97    $31.97   \n",
      "\n",
      "         Date  \n",
      "0  2024-06-09  \n",
      "1  2024-06-09  \n",
      "2  2024-06-09  \n",
      "3  2024-06-09  \n",
      "4  2024-06-09  \n",
      "5  2024-06-09  \n",
      "6  2024-06-09  \n",
      "7  2024-06-09  \n",
      "8  2024-06-09  \n",
      "9  2024-06-09  \n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\sseja\\AmazonWebScaperData.csv\")#r se you do not need to change back slashes\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc961d25-73a7-487c-8589-f75adc561e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881fae9f-cd89-4040-a809-2d20d6c48d62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
